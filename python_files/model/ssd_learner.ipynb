{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aae683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib\n",
    "\n",
    "import cv2\n",
    "import random\n",
    "import math\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os import path\n",
    "from os.path import isfile, join\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K#.concatenate\n",
    "\n",
    "import tensorflow_io as tfio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94a019e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from ssd_settings import *\n",
    "from ssd_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152133fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# box converter\n",
    "class BoxConverter:\n",
    "    def _prepareDefaultBoxes(self):\n",
    "        \n",
    "        max_box_size = 38\n",
    "        num_boxes = list()\n",
    "        self.layer_widths = list()\n",
    "        for sz in self.box_sizes:\n",
    "            self.layer_widths.append(max_box_size)\n",
    "            num_boxes.append(len(sz))\n",
    "\n",
    "            max_box_size = math.ceil(max_box_size/2)\n",
    "            \n",
    "        assert len(self.box_sizes) == len(num_boxes)\n",
    "        assert len(self.box_sizes) == len(self.layer_widths)\n",
    "\n",
    "        self.total_boxes_num = sum([lw*lw*nb for lw,nb in zip(self.layer_widths, num_boxes)])\n",
    "        \n",
    "        self.centers      = np.zeros((self.total_boxes_num, 2), dtype=np.float32)\n",
    "        self.wh           = np.zeros((self.total_boxes_num, 2), dtype=np.float32)\n",
    "        self.boxes_coords = np.zeros((self.total_boxes_num, 4), dtype=np.float32)\n",
    "        print(\"total_boxes_num:\", self.total_boxes_num)\n",
    "\n",
    "        # calculating the default box centers and width,height\n",
    "        idx = 0\n",
    "        for grid_size, box_size in zip(self.layer_widths, self.box_sizes):\n",
    "            step_size = self.image_size * 1.0 / grid_size\n",
    "            \n",
    "            for i in range(grid_size):\n",
    "                for j in range(grid_size):\n",
    "                    pos = idx + (i*grid_size+j) * len(box_size)\n",
    "\n",
    "                    # same centers for all aspect ratios\n",
    "                    self.centers[pos : pos + len(box_size), :] = j*step_size + step_size/2, i*step_size + step_size/2\n",
    "                    self.wh[pos : pos + len(box_size), :] = box_size\n",
    "\n",
    "            idx += grid_size * grid_size * len(box_size)\n",
    "\n",
    "        # (x,y) coordinates of top left and bottom right\n",
    "        self.boxes_coords[:,0] = self.centers[:,0] - self.wh[:,0]/2\n",
    "        self.boxes_coords[:,1] = self.centers[:,1] - self.wh[:,1]/2\n",
    "        self.boxes_coords[:,2] = self.centers[:,0] + self.wh[:,0]/2\n",
    "        self.boxes_coords[:,3] = self.centers[:,1] + self.wh[:,1]/2\n",
    "        \n",
    "        print(\"default boxes are ready\")\n",
    "        \n",
    "    def _adjustDataForNewSize(self, x, y, width, height, old_size=(640,480), new_size=(image_size,image_size)):\n",
    "        x = x * new_size[0] // old_size[0]\n",
    "        y = y * new_size[1] // old_size[1]\n",
    "        width  = width * new_size[0] // old_size[0]\n",
    "        height = height * new_size[1] // old_size[1]\n",
    "\n",
    "        return x,y,width,height\n",
    "\n",
    "    def _readLabelFileData(self, path):\n",
    "        label_data = []\n",
    "        with open(path) as f:\n",
    "            for label in f.readlines():\n",
    "                class_label, x, y, width, height = [\n",
    "                    float(x) if float(x) != int(float(x)) else int(x)\n",
    "                    for x in label.replace(\"\\n\", \"\").split()\n",
    "                ]\n",
    "\n",
    "                label_data.append([class_label, x, y, width, height])\n",
    "        return label_data\n",
    "    \n",
    "    def _labelDataToBoxes(self,label_data):\n",
    "        output = np.zeros((self.total_boxes_num, 1 + 4))# class_number, center(x,y), w, h\n",
    "        output[:,0] = self.total_classes\n",
    "\n",
    "        for cls,x,y,width,height in label_data:\n",
    "            x_coord_0, y_coord_0, width, height = self._adjustDataForNewSize(x,y,width,height)\n",
    "\n",
    "            # 0\n",
    "            bbox = np.zeros(4)\n",
    "            bbox[:2] = [x_coord_0, y_coord_0]\n",
    "            bbox[2:] = [x_coord_0+width, y_coord_0+height]\n",
    "\n",
    "            # all default boxes with IoU > threshold\n",
    "            box_idxs = bestIoU(bbox, self.boxes_coords, self.total_boxes_num, threshold=0.5)#.astype(np.uint16)\n",
    "            #print(\"boxes found:\", len(box_idxs))\n",
    "            \n",
    "            output[box_idxs,0] = cls\n",
    "            output[box_idxs,1] = (bbox[0] + bbox[2])/2.0 - self.centers[box_idxs,0]\n",
    "            output[box_idxs,2] = (bbox[1] + bbox[3])/2.0 - self.centers[box_idxs,1]\n",
    "            output[box_idxs,3] = width - self.wh[box_idxs,1]\n",
    "            output[box_idxs,4] = height - self.wh[box_idxs,0]\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def generateSaveSsdBoxes(self):\n",
    "        # get image filenames without extension\n",
    "        indexes = [int(f[:-4]) for f in listdir(self.data_dir) if f[-3:] == 'png']\n",
    "        \n",
    "        for idx in indexes:\n",
    "            # get label txt-file path\n",
    "            path = os.path.join(self.data_dir, str(idx) + '.txt')\n",
    "            \n",
    "            label_data = self._readLabelFileData(path)\n",
    "            generated_boxes = self._labelDataToBoxes(label_data).astype(np.float32)\n",
    "\n",
    "            # save\n",
    "            if self.is_save:\n",
    "                npy_path = os.path.join(self.data_dir, str(idx) + '.npy')\n",
    "                np.save(npy_path, generated_boxes)\n",
    "                \n",
    "    def _xywh_to_points(self, xywh, box_num):\n",
    "        \"\"\"\n",
    "            calculate and return start point and end point\n",
    "        \"\"\"\n",
    "        box_center_x_y = self.centers[box_num] + xywh[:2]\n",
    "        box_wh = self.wh[box_num] + xywh[2:]\n",
    "\n",
    "        x = box_center_x_y[0] - box_wh[0]/2\n",
    "        y = box_center_x_y[1] - box_wh[1]/2\n",
    "\n",
    "        start_point = (int(x), int(y))\n",
    "        end_point   = (int(x + box_wh[0]), int(y + box_wh[1]))\n",
    "\n",
    "        return start_point, end_point\n",
    "    \n",
    "    def get_best_boxes(self,y_pred, output_channels, threshold=0.8):\n",
    "\n",
    "        class_predictions = tf.nn.softmax(y_pred[:,:output_channels-4],axis=1)\n",
    "        box_max_class = np.argmax(class_predictions, axis=-1)# list of classes with highest probability in box\n",
    "\n",
    "        assert len(box_max_class) == len(y_pred)\n",
    "\n",
    "        recognized_data = list()\n",
    "\n",
    "        for box_pos in range(len(class_predictions)):\n",
    "            # check if class is background\n",
    "            if num_classes == box_max_class[box_pos]:\n",
    "                continue\n",
    "            # get max value\n",
    "            val = class_predictions[box_pos, box_max_class[box_pos]]\n",
    "            #print(val)\n",
    "            if val > threshold:\n",
    "                start_point, end_point = self._xywh_to_points(y_pred[box_pos, output_channels-4:], box_pos)\n",
    "\n",
    "                recognized_data.append(RecognitionData(box_max_class[box_pos], val, start_point, end_point))\n",
    "\n",
    "        return recognized_data\n",
    "    \n",
    "    def get_best_boxes_label(self, y_label):\n",
    "        box_pos = np.argwhere(y_label[:,0] != num_classes)\n",
    "        \n",
    "        recognized_data = list()\n",
    "\n",
    "        for pos in box_pos:\n",
    "            pos = pos[0]\n",
    "            val = y_label[pos]\n",
    "            start_point, end_point = self._xywh_to_points(val[-4:], pos)\n",
    "\n",
    "            recognized_data.append(RecognitionData(int(val[0]), 1.0, start_point, end_point))\n",
    "\n",
    "        return recognized_data\n",
    "    \n",
    "    def getUniqueBoxes(self, found_boxes):\n",
    "        unique_boxes = []\n",
    "        for bx in found_boxes:\n",
    "            found = False\n",
    "            for ubx in unique_boxes:\n",
    "                if ubx.class_num == bx.class_num and ubx.start_point == bx.start_point and ubx.end_point == bx.end_point:\n",
    "                    found = True\n",
    "                    break\n",
    "            if found == False:\n",
    "                unique_boxes.append(bx)\n",
    "\n",
    "        return unique_boxes\n",
    "    \n",
    "    def calc_mAP_f1(self, detections, ground_truths, threshold=0.5):\n",
    "        epsilon = 1e-6\n",
    "\n",
    "        tp = 0\n",
    "\n",
    "        for gt in ground_truths:\n",
    "            for det in detections:\n",
    "                # for same class\n",
    "                if det.class_num == gt.class_num:\n",
    "                    iou = IoU(np.array([[det.start_point[0], det.start_point[1], det.end_point[0], det.end_point[1]]]),\n",
    "                             np.array([[gt.start_point[0], gt.start_point[1], gt.end_point[0], gt.end_point[1]]]))\n",
    "\n",
    "                    if iou > threshold:\n",
    "                        tp += 1\n",
    "                        break\n",
    "\n",
    "        recall = tp / (len(detections) + epsilon)\n",
    "        precision = tp / (len(ground_truths) + epsilon)\n",
    "\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + epsilon)\n",
    "\n",
    "        return f1\n",
    "    \n",
    "    \n",
    "    def _saveBinArrayToFile(self, filename, data):\n",
    "        # write to file\n",
    "        new_file = open(filename, \"wb\")\n",
    "        new_file.write(data.tobytes())\n",
    "        \n",
    "    def saveBoxData(self):\n",
    "        \"\"\"\n",
    "            saves centers and wh arrays to binary files\n",
    "        \"\"\"\n",
    "        self._saveBinArrayToFile(os.path.join(output_dir, \"centers.bin\"), self.centers)\n",
    "        self._saveBinArrayToFile(os.path.join(output_dir, \"wh.bin\"), self.wh)\n",
    "    \n",
    "    def show_layer_boxes(self):\n",
    "        COLOR_VIOLET = (226,43, 138)\n",
    "        COLOR_GREEN  = (34, 139,34)\n",
    "        COLOR_PINK   = (133,21, 199)\n",
    "        COLOR_ORANGE = (0,  140,255)\n",
    "\n",
    "        pos = 0\n",
    "        \n",
    "        for grid_size in self.layer_widths:\n",
    "            print(\"show grid of\", grid_size)\n",
    "            \n",
    "            image = np.zeros([image_size,image_size,3], dtype=np.uint8)\n",
    "\n",
    "            for x in range(grid_size):\n",
    "                for y in range(grid_size):\n",
    "                    center_position = self.centers[pos].astype(np.int32)\n",
    "                    cv2.circle(image, center_position, 1, (0,0,255), 1)\n",
    "\n",
    "                    # show boxes in the middle of image\n",
    "                    if x == grid_size//2 and y == grid_size//2:\n",
    "                        wh_values0 = (self.wh[pos+0].astype(np.int32)) // 2\n",
    "                        wh_values1 = (self.wh[pos+1].astype(np.int32)) // 2\n",
    "                        wh_values2 = (self.wh[pos+2].astype(np.int32)) // 2\n",
    "                        wh_values3 = (self.wh[pos+3].astype(np.int32)) // 2\n",
    "\n",
    "                        start_pos0 = center_position - wh_values0\n",
    "                        end_pos0   = center_position + wh_values0\n",
    "                        start_pos1 = center_position - wh_values1\n",
    "                        end_pos1   = center_position + wh_values1\n",
    "                        start_pos2 = center_position - wh_values2\n",
    "                        end_pos2   = center_position + wh_values2\n",
    "                        start_pos3 = center_position - wh_values3\n",
    "                        end_pos3   = center_position + wh_values3\n",
    "\n",
    "                        cv2.rectangle(image, start_pos0, end_pos0, COLOR_VIOLET, 1)\n",
    "                        cv2.rectangle(image, start_pos1, end_pos1, COLOR_GREEN,  1)\n",
    "                        cv2.rectangle(image, start_pos2, end_pos2, COLOR_PINK,   1)\n",
    "                        cv2.rectangle(image, start_pos3, end_pos3, COLOR_ORANGE, 1)\n",
    "                    \n",
    "                    pos += box_sizes.shape[1]# 4\n",
    "\n",
    "            cv2.imshow(\"image\", image)\n",
    "            cv2.waitKey(1000)\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    def __init__(self, box_sizes_, image_size_, total_classes_, data_dir_, is_save_):\n",
    "        \n",
    "        self.box_sizes = box_sizes_\n",
    "        self.image_size = image_size_\n",
    "        self.total_classes = total_classes_\n",
    "        self.data_dir = data_dir_\n",
    "        self.is_save = is_save_\n",
    "        \n",
    "        # prepare default boxes: centers, wh, boxes\n",
    "        self._prepareDefaultBoxes()\n",
    "        \n",
    "        # txt to npy\n",
    "        self.generateSaveSsdBoxes()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1353d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowPredCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, epochs_, check_image_, check_label_, box_converter_, learning_rates_):\n",
    "        self.epochs = epochs_\n",
    "        self.check_image = check_image_\n",
    "        self.check_label = check_label_\n",
    "        self.box_converter = box_converter_\n",
    "        \n",
    "        self.learning_rates = learning_rates_\n",
    "        self.lr_pos_step = self.epochs // len(self.learning_rates)\n",
    "        self.lr_position = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        predicted = self.model.predict(self.check_image)\n",
    "\n",
    "        recognized_data = self.box_converter.get_best_boxes(predicted[0], output_channels, 0.5)\n",
    "        recognized_data = np.array(non_max_suppression(recognized_data, 0.3, 0.65))# nms\n",
    "        \n",
    "        \"\"\"\n",
    "        # correct labels\n",
    "        correct_data = self.box_converter.get_best_boxes_label(self.check_label)\n",
    "        correct_data = self.box_converter.getUniqueBoxes(correct_data)\n",
    "        \n",
    "        # mean average precision\n",
    "        f1_score = self.box_converter.calc_mAP_f1(recognized_data, correct_data)\n",
    "        print(\" mAP f1 on 1 picture: {:.4f}\", f1_score)\n",
    "        \n",
    "        if epoch == 30:\n",
    "            print(\"epoch 30\")\n",
    "            for cd in correct_data:\n",
    "                print(\"cd:\", cd)\n",
    "            for rd in recognized_data:\n",
    "                print(\"rd:\", rd)\n",
    "        \"\"\"\n",
    "        # clone image\n",
    "        image = self.check_image[0].numpy().copy()\n",
    "\n",
    "        # draw\n",
    "        draw_all_rectanges(image, recognized_data)\n",
    "        #draw_all_rectanges(image, correct_data)\n",
    "        #draw_average_rectangle(image, recognized_data)\n",
    "\n",
    "        image = cv2.resize(image, (600,600))\n",
    "        cv2.imshow(\"check image\", image)\n",
    "        cv2.waitKey(1)\n",
    "        \n",
    "        # change learning rate\n",
    "        if epoch > 0 and epoch % self.lr_pos_step == 0:\n",
    "            self.lr_position += 1\n",
    "            self.model.optimizer.lr.assign(self.learning_rates[self.lr_position])\n",
    "            print(\"\\n\\nlearning rate:\", self.model.optimizer.lr.read_value().numpy())\n",
    "            \n",
    "        # for last epoch\n",
    "        if epoch == (self.epochs - 1):\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "\n",
    "@tf.function\n",
    "def prepare_image_tensor(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.io.decode_png(image,channels=3)\n",
    "    #img_h, img_w  = image.shape[:2]\n",
    "    \n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    image = tf.image.resize(image, [image_size, image_size])\n",
    "    \n",
    "    # random change of colors\n",
    "    image = tf.image.adjust_saturation(image, tf.random.uniform([], maxval=5, dtype=tf.float32))\n",
    "    image = tf.image.stateless_random_brightness(\n",
    "        image, max_delta=0.2,seed=tf.random.uniform([2], maxval=5, dtype=tf.int32))\n",
    "    image = tf.image.stateless_random_contrast(\n",
    "        image, lower=0.5, upper=0.9, seed=tf.random.uniform([2], maxval=5, dtype=tf.int32))\n",
    "    \n",
    "    image = tfio.experimental.color.bgr_to_rgb(image)\n",
    "    \n",
    "    return image\n",
    "\n",
    "@tf.function\n",
    "def prepareLabelData(label_path):\n",
    "    data = tf.io.read_file(label_path)\n",
    "    data = tf.io.decode_raw(data, tf.float32)\n",
    "    data = data[32:]\n",
    "    data = tf.reshape(data, [7720, 5])\n",
    "\n",
    "    return data\n",
    "\n",
    "@tf.function\n",
    "def prepare_image_data(filename):\n",
    "    img_path = data_dir + tf.strings.as_string(filename) + '.png'\n",
    "    label_path = data_dir + tf.strings.as_string(filename) + '.npy'\n",
    "\n",
    "    img = prepare_image_tensor(img_path)\n",
    "    label = prepareLabelData(label_path)\n",
    "\n",
    "    return (img,label,)\n",
    "\n",
    "class SsdModelTrainer:\n",
    "    def _splitFolderImageNames(self, image_dir_path, train_split_percentage):\n",
    "        \"\"\"\n",
    "            return train, test and validation lists (in INTEGER format) of png-file names\n",
    "        \"\"\"\n",
    "\n",
    "        all_image_pathes = [int(f[:-4]) for f in listdir(image_dir_path) if f[-3:] == 'png']\n",
    "        random.shuffle(all_image_pathes)\n",
    "\n",
    "        files_number = len(all_image_pathes)\n",
    "        train_number = files_number * train_split_percentage // 100\n",
    "        train_files = all_image_pathes[:train_number]\n",
    "\n",
    "        test_number = (files_number - train_number) // 2\n",
    "        test_files = all_image_pathes[train_number:(train_number + test_number)]\n",
    "        valid_files = all_image_pathes[(train_number + test_number):]\n",
    "\n",
    "        return train_files, test_files, valid_files\n",
    "    \n",
    "    def _prepareDataset(self,):\n",
    "        train_files, test_files, valid_files = self._splitFolderImageNames(self.data_dir, train_split_percentage=80)\n",
    "        len(train_files), len(test_files), len(valid_files)\n",
    "        \n",
    "        BATCH_SIZE = 16\n",
    "        dataset_train = tf.data.Dataset.from_tensor_slices(train_files).shuffle(64)\n",
    "        dataset_train = dataset_train.map(prepare_image_data)\n",
    "        self.dataset_train = dataset_train.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        dataset_test = tf.data.Dataset.from_tensor_slices(test_files)\n",
    "        dataset_test = dataset_test.map(prepare_image_data)\n",
    "        self.dataset_test = dataset_test.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        dataset_valid = tf.data.Dataset.from_tensor_slices(valid_files)\n",
    "        dataset_valid = dataset_valid.map(prepare_image_data)\n",
    "        self.dataset_valid = dataset_valid.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "        \n",
    "        # get image for test\n",
    "        for check_image, check_label in self.dataset_train.take(1):\n",
    "            pass\n",
    "        self.check_image = tf.expand_dims(check_image[0], axis=0)\n",
    "        self.check_label = check_label[0]\n",
    "        print(self.check_image.shape, self.check_label.shape)\n",
    "        \n",
    "        \n",
    "    def _buildModel(self):\n",
    "        backbone = tf.keras.applications.MobileNetV2(\n",
    "                include_top=False, input_shape=[image_size, image_size, 3], weights='imagenet'\n",
    "            )\n",
    "        backbone.trainable = False\n",
    "\n",
    "        for layer in backbone.layers:\n",
    "            layer.trainable = False\n",
    "        #keras.utils.plot_model(backbone, \"backbone.png\", show_shapes=True)\n",
    "\n",
    "        output0 = backbone.get_layer('block_6_expand_relu')\n",
    "        output1 = backbone.get_layer('block_13_expand_relu')\n",
    "\n",
    "        conv0 = tf.keras.layers.Conv2D(256,1,strides=1,padding='same',activation='relu',kernel_initializer='he_normal',name='SSD_11')(output1.output)\n",
    "        conv1 = tf.keras.layers.Conv2D(512,3,strides=2,padding='same',activation='relu',kernel_initializer='he_normal',name='SSD_12')(conv0)\n",
    "        conv2 = tf.keras.layers.Conv2D(128,1,strides=1,padding='same',activation='relu',kernel_initializer='he_normal',name='SSD_21')(conv1)\n",
    "        conv3 = tf.keras.layers.Conv2D(256,3,strides=2,padding='same',activation='relu',kernel_initializer='he_normal',name='SSD_22')(conv2)\n",
    "        conv4 = tf.keras.layers.Conv2D(128,1,strides=1,padding='same',activation='relu',kernel_initializer='he_normal',name='SSD_31')(conv3)\n",
    "\n",
    "        DROPOUT_VALUE = 0.5\n",
    "        drop0 = tf.keras.layers.Dropout(DROPOUT_VALUE)(output0.output)\n",
    "        drop1 = tf.keras.layers.Dropout(DROPOUT_VALUE)(output1.output)\n",
    "        drop2 = tf.keras.layers.Dropout(DROPOUT_VALUE)(conv1)\n",
    "        drop3 = tf.keras.layers.Dropout(DROPOUT_VALUE)(conv3)\n",
    "\n",
    "        class0 = tf.keras.layers.Conv2D(4*output_channels,3,strides=1,padding='same',kernel_initializer='he_normal')(drop0)#0\n",
    "        class1 = tf.keras.layers.Conv2D(4*output_channels,3,strides=1,padding='same',kernel_initializer='he_normal')(drop1)#1\n",
    "        class2 = tf.keras.layers.Conv2D(4*output_channels,3,strides=1,padding='same',kernel_initializer='he_normal')(drop2)#2\n",
    "        class3 = tf.keras.layers.Conv2D(4*output_channels,3,strides=1,padding='same',kernel_initializer='he_normal')(drop3)#3\n",
    "\n",
    "        class0_flatten = tf.keras.layers.Flatten()(class0)\n",
    "        class1_flatten = tf.keras.layers.Flatten()(class1)\n",
    "        class2_flatten = tf.keras.layers.Flatten()(class2)\n",
    "        class3_flatten = tf.keras.layers.Flatten()(class3)\n",
    "\n",
    "        # concatenate all the classifiers\n",
    "        conc = K.concatenate([class0_flatten,\n",
    "                              class1_flatten,\n",
    "                              class2_flatten,\n",
    "                              class3_flatten], axis=-1)\n",
    "        out = tf.keras.layers.Reshape((-1, output_channels))(conc)\n",
    "\n",
    "        mm = tf.keras.models.Model(\n",
    "            inputs=backbone.input,\n",
    "            outputs=out\n",
    "            )\n",
    "\n",
    "        return mm\n",
    "        \n",
    "    def __init__(self, data_dir_, box_converter_):\n",
    "        self.data_dir = data_dir_\n",
    "        self.box_converter = box_converter_\n",
    "        \n",
    "        # prepare dataset\n",
    "        self._prepareDataset()\n",
    "        \n",
    "        # prepare model\n",
    "        self.model = self._buildModel()\n",
    "        #self.model.summary()\n",
    "        \n",
    "    def train(self, learning_rates, epochs=40):\n",
    "        drawCallback = ShowPredCallback(epochs, self.check_image, self.check_label, self.box_converter, learning_rates)\n",
    "        \n",
    "        self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rates[0]),loss=Loss)\n",
    "        history = self.model.fit(self.dataset_train, epochs=epochs,\n",
    "                        callbacks=[drawCallback],\n",
    "                        validation_data=self.dataset_valid)\n",
    "\n",
    "    def showTestResults(self, is_dataset_test=True):\n",
    "        if is_dataset_test:\n",
    "            for test_image, test_label in self.dataset_test.take(1):\n",
    "                pass\n",
    "        else:\n",
    "            for test_image, test_label in self.dataset_train.take(1):\n",
    "                pass\n",
    "\n",
    "        for TEST_IMAGE_NUMBER in range(test_image.shape[0]):\n",
    "            for_test = test_image[TEST_IMAGE_NUMBER]\n",
    "            for_test = tf.reshape(for_test, [1,image_size,image_size,3])\n",
    "\n",
    "            predicted = self.model.predict(for_test)\n",
    "\n",
    "            recognized_data = self.box_converter.get_best_boxes(predicted[0], output_channels,0.5)\n",
    "            \n",
    "            recognized_data = np.array(non_max_suppression(recognized_data, 0.1, 0.65))# nms\n",
    "            for dt in recognized_data:\n",
    "                print(dt)\n",
    "            print(\"-----------\")\n",
    "\n",
    "            # clone image\n",
    "            image = for_test[0].numpy().copy()\n",
    "\n",
    "            # draw\n",
    "            draw_all_rectanges(image, recognized_data)\n",
    "\n",
    "            image = cv2.resize(image, [600,600])\n",
    "            cv2.imshow(\"check image\", image)\n",
    "            cv2.waitKey(1001)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        \n",
    "    def convertToSupportedFormat(self):\n",
    "        \"\"\"\n",
    "            Installed OpenCV doesn't support reshape layers.\n",
    "            This conversion instead of reshaping, concatenates outputs.\n",
    "\n",
    "        \"\"\"\n",
    "        # convert \n",
    "        out0 = self.model.layers[-6]\n",
    "        out1 = self.model.layers[-5]\n",
    "        out2 = self.model.layers[-4]\n",
    "        out3 = self.model.layers[-3]\n",
    "\n",
    "        conc = K.concatenate([out0.output,out1.output, out2.output, out3.output], axis=-1)\n",
    "\n",
    "        supported_model = tf.keras.models.Model(\n",
    "            inputs=self.model.input,\n",
    "            outputs=[conc]\n",
    "            )\n",
    "        \n",
    "        return supported_model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e646499",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_converter = BoxConverter(box_sizes, image_size, num_classes, data_dir, is_save_=True)\n",
    "#box_converter.show_layer_boxes()\n",
    "trainer = SsdModelTrainer(data_dir, box_converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efea768",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [1e-3]#, 1e-4, 1e-5, 1e-6]\n",
    "trainer.train(learning_rates, 40)# 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e529d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cb9ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test results\n",
    "trainer.showTestResults(is_dataset_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3798ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "# centers.bin\n",
    "# wh.bin\n",
    "box_converter.saveBoxData()\n",
    "\n",
    "# convert model to supported format\n",
    "supported_model = trainer.convertToSupportedFormat()\n",
    "# save model's .h5-file\n",
    "supported_model.save(os.path.join(output_dir, h5_model_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d4f12c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b0300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# VGG16 SSD 300\n",
    "x1 = tf.keras.layers.InputLayer(input_shape=[300, 300, 3])\n",
    "#x1 = Input(shape=(300, 300, 3))\n",
    "conv1_1 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', name='conv1_1')(x1.output)\n",
    "conv1_2 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', name='conv1_2')(conv1_1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name='pool1')(conv1_2)\n",
    "\n",
    "conv2_1 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', name='conv2_1')(pool1)\n",
    "conv2_2 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', name='conv2_2')(conv2_1)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name='pool2')(conv2_2)\n",
    "\n",
    "conv3_1 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', name='conv3_1')(pool2)\n",
    "conv3_2 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', name='conv3_2')(conv3_1)\n",
    "conv3_3 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', name='conv3_3')(conv3_2)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name='pool3')(conv3_3)\n",
    "\n",
    "conv4_1 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', name='conv4_1')(pool3)\n",
    "conv4_2 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', name='conv4_2')(conv4_1)\n",
    "conv4_3 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', name='conv4_3')(conv4_2)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name='pool4')(conv4_3)\n",
    "\n",
    "conv5_1 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', name='conv5_1')(pool4)\n",
    "conv5_2 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', name='conv5_2')(conv5_1)\n",
    "conv5_3 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', name='conv5_3')(conv5_2)\n",
    "pool5 = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='same', name='pool5')(conv5_3)\n",
    "\n",
    "fc6 = Conv2D(1024, (3, 3), dilation_rate=(6, 6), activation='relu', padding='same', kernel_initializer='he_normal', name='fc6')(pool5)\n",
    "\n",
    "fc7 = Conv2D(1024, (1, 1), activation='relu', padding='same', kernel_initializer='he_normal', name='fc7')(fc6)\n",
    "\n",
    "conv6_1 = Conv2D(256, (1, 1), activation='relu', padding='same', kernel_initializer='he_normal', name='conv6_1')(fc7)\n",
    "conv6_1 = ZeroPadding2D(padding=((1, 1), (1, 1)), name='conv6_padding')(conv6_1)\n",
    "conv6_2 = Conv2D(512, (3, 3), strides=(2, 2), activation='relu', padding='valid', kernel_initializer='he_normal', name='conv6_2')(conv6_1)\n",
    "\n",
    "conv7_1 = Conv2D(128, (1, 1), activation='relu', padding='same', kernel_initializer='he_normal', name='conv7_1')(conv6_2)\n",
    "conv7_1 = ZeroPadding2D(padding=((1, 1), (1, 1)), name='conv7_padding')(conv7_1)\n",
    "conv7_2 = Conv2D(256, (3, 3), strides=(2, 2), activation='relu', padding='valid', kernel_initializer='he_normal', name='conv7_2')(conv7_1)\n",
    "\n",
    "conv8_1 = Conv2D(128, (1, 1), activation='relu', padding='same', kernel_initializer='he_normal', name='conv8_1')(conv7_2)\n",
    "conv8_2 = Conv2D(256, (3, 3), strides=(1, 1), activation='relu', padding='valid', kernel_initializer='he_normal', name='conv8_2')(conv8_1)\n",
    "\n",
    "conv9_1 = Conv2D(128, (1, 1), activation='relu', padding='same', kernel_initializer='he_normal', name='conv9_1')(conv8_2)\n",
    "conv9_2 = Conv2D(256, (3, 3), strides=(1, 1), activation='relu', padding='valid', kernel_initializer='he_normal', name='conv9_2')(conv9_1)\n",
    "#model = tf.keras.models.Model(inputs=x1.input, outputs=conv9_2)\n",
    "\n",
    "\n",
    "# We precidt `n_classes` confidence values for each box, hence the confidence predictors have depth `n_boxes * n_classes`\n",
    "# Output shape of the confidence layers: `(batch, height, width, n_boxes * n_classes)`\n",
    "# We predict 4 box coordinates for each box, hence the localization predictors have depth `n_boxes * 4`\n",
    "# Output shape of the localization layers: `(batch, height, width, n_boxes * 4)`\n",
    "\n",
    "class0 = layers.Conv2D(4*15,3,padding='same')(conv4_3)#0\n",
    "class1 = layers.Conv2D(4*15,3,padding='same')(fc7)#1\n",
    "class2 = layers.Conv2D(4*15,3,padding='same')(conv6_2)#2\n",
    "class3 = layers.Conv2D(4*15,3,padding='same')(conv7_2)#3\n",
    "class4 = layers.Conv2D(4*15,3,padding='same')(conv8_2)#4\n",
    "class5 = layers.Conv2D(4*15,3,padding='same')(conv9_2)#5\n",
    "\n",
    "class0_resh = layers.Reshape((-1, 15))(class0)\n",
    "class1_resh = layers.Reshape((-1, 15))(class1)\n",
    "class2_resh = layers.Reshape((-1, 15))(class2)\n",
    "class3_resh = layers.Reshape((-1, 15))(class3)\n",
    "class4_resh = layers.Reshape((-1, 15))(class4)\n",
    "class5_resh = layers.Reshape((-1, 15))(class5)\n",
    "\n",
    "# concatenate all the classifiers\n",
    "out = layers.concatenate([class0_resh,class1_resh,class2_resh,class3_resh,class4_resh,class5_resh], axis = -2, name='concatenate')\n",
    "\n",
    "mm = tf.keras.models.Model(\n",
    "    inputs=x1.input,\n",
    "    outputs=out\n",
    "    )\n",
    "mm.summary()\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4d0cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
